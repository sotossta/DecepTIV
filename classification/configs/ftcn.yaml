model:
  name: FTCN  

backbone:
  name: Clip
  num_classes: 2
  clip_size: 8
  pretrained: ./pretrained/ViT-B-16.pt # path to a pre-trained model, if using one

# mean and std for normalization
mean: [0.5, 0.5, 0.5]
std: [0.5, 0.5, 0.5]

train_batchsize: 16   # training batch size
val_batchsize: 16   # validation batch size
test_batchsize: 16   # test batch size

resolution: 224   # resolution of input image to network

# optimizer config
optimizer:
  type: adam
  adam:
    lr: 0.000002  # learning rate  # learning rate
    beta1: 0.9  # beta1 for Adam optimizer
    beta2: 0.999 # beta2 for Adam optimizer
    eps: 0.00000001  # epsilon for Adam optimizer
    weight_decay: 0.0005  # weight decay for regularization
    amsgrad: false
  sgd:
    lr: 0.0002  # learning rate
    momentum: 0.9  # momentum for SGD optimizer
    weight_decay: 0.0005  # weight decay for regularization

# training config
lr_scheduler: null   # learning rate scheduler
nEpochs: 10   # number of epochs to train for
start_epoch: 0   # manual epoch number (useful for restarts)
manualSeed: 1024   # manual seed for random number generation

# loss function
loss_func: cross_entropy 

#Logging
log_interval: 100 # How often to log training process

#Save models
save_dir:  /sotossta/DecepTIV/classification/ckpts

#ckpt testing
ckpt_test: model_epoch8_val0.9968.tar

# cuda
cuda: true   # whether to use CUDA acceleration